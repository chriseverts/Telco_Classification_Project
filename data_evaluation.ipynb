{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59955b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import acquire, prepare, warnings\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def confusion_table(df: pd.DataFrame) -> str:\n",
    "    '''Takes DataFrame and prints a formatted Confusion Table/Matrix in\n",
    "    markdown for Juypter notebooks. The first column must be the actual values and all\n",
    "    the other columns have to be model values or predicted values.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    df : pandas DataFrame\n",
    "        Requires the 'actual' values to be the first column \n",
    "        and all other columns to be the predicted values.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    str \n",
    "        string that is formatted with HTML and markdown\n",
    "        for Juypter Notebooks so that it can be copied and pasted into a \n",
    "        markdown cell and easier to view the values.\n",
    "        \n",
    "    '''\n",
    "    result = str()\n",
    "    table_names = str()\n",
    "    tables = str()\n",
    "    actual = df.columns[0]\n",
    "    col_names = [str(col) for col in df.columns if col != actual]\n",
    "    for col in col_names:\n",
    "        table_names += f'<th><center>{str(col.capitalize())}</center></th>'\n",
    "    for col in col_names:\n",
    "        \n",
    "        # Crosstab the model row vs the actual values\n",
    "        val = pd.crosstab(df[col], df[actual], rownames=['Prediction'], colnames=['Actual']).reset_index()\n",
    "        \n",
    "        # Generate report values, precision, recall, accuracy\n",
    "        report = pd.DataFrame(classification_report(df[actual], df[col], output_dict=True))\n",
    "        \n",
    "        # Get all the uniques in a list\n",
    "        uniques = [str(col) for col in val.columns if col not in ['Prediction']]\n",
    "        \n",
    "        # Make a line break in table for Accuracy\n",
    "        accuracy_row = ['Accuracy']\n",
    "        accuracy_row.extend(['-----' for n in range(len(uniques))])\n",
    "        accuracy_row[-1] = report.accuracy[0] * 100\n",
    "        \n",
    "        # Ensure all columns names are strings\n",
    "        val = val.rename(columns=lambda x: str(x))\n",
    "        \n",
    "        # Create a divider of len n\n",
    "        divider = ['-----' for n in range(len(uniques)+1)]\n",
    "        val.loc[len(val.index)] = divider\n",
    "        # Input the accuracy\n",
    "        val.loc[len(val.index)] = accuracy_row\n",
    "        val.loc[len(val.index)] = divider\n",
    "        \n",
    "        for unique in uniques:\n",
    "            # Iterate through all uniques and fetch their precision, \n",
    "            # recall, f1-score and support values to put into the table.\n",
    "            precision = report[str(unique)][0] * 100\n",
    "            recall = report[str(unique)][1] * 100\n",
    "            f1_score = report[str(unique)][2] * 100\n",
    "            support = report[str(unique)][3]\n",
    "            df2 = [{'Prediction': 'Precision', unique: precision},\n",
    "                  {'Prediction': 'Recall', unique: recall},\n",
    "                  {'Prediction': 'f1-score', unique: f1_score},\n",
    "                  {'Prediction': 'support', unique: support}]\n",
    "            \n",
    "            # Add the values to the bottom of the table\n",
    "            val = val.append(df2, ignore_index=True)\n",
    "        \n",
    "        # Collapse the index under Prediction to have the table smaller\n",
    "        new_df = val.set_index('Prediction')\n",
    "        # Put the table to markdown\n",
    "        tab = new_df.to_markdown()\n",
    "        \n",
    "        \n",
    "        tables += f'<td>\\n\\n{tab}\\n\\n</td>\\n\\n'\n",
    "\n",
    "    result += f'''<div><center><h3>{actual}</h3>\n",
    "    <table>\n",
    "    <tr>{table_names}</tr>\n",
    "    <tr>{tables}</tr></table></center></div>'''\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def replace_obj_cols(daf: pd.DataFrame, dropna=False) -> (pd.DataFrame, dict, dict):\n",
    "    '''Takes a DataFrame and will return a DataFrame that has\n",
    "    all objects replaced with int values and the respective keys are return\n",
    "    and a revert key is also generated.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    df : pandas DataFrame\n",
    "        Will take all object/str based column data types and convert their values\n",
    "        to integers to be input into a ML algorithm.\n",
    "    \n",
    "    dropna: bool\n",
    "        If this is True, it will drop all rows with any column that has NaN \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame \n",
    "        The returned DataFrame has all the str/object values replaced with integers\n",
    "        \n",
    "    dict - replace_key\n",
    "        The returned replace_key shows what values replaced what str\n",
    "        \n",
    "    dict - revert_key\n",
    "        The returned revert_key allows it to be put into a df.replace(revert_key) \n",
    "        to put all the original values back into the DataFrame\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    >>>dt = {'Sex':['male', 'female', 'female', 'male', 'male'],\n",
    "        'Room':['math', 'math', 'gym', 'gym', 'reading'],\n",
    "        'Age':[11, 29, 15, 16, 14]}\n",
    "    >>>test = pd.DataFrame(data=dt)\n",
    "    \n",
    "    >>>test, rk, revk  = replace_obj_cols(test)\n",
    "       Sex  Room  Age\n",
    "    0    0     0   11\n",
    "    1    1     0   29\n",
    "    2    1     1   15\n",
    "    3    0     1   16\n",
    "    4    0     2   14,\n",
    "    \n",
    "    {'Sex': {'male': 0, 'female': 1},\n",
    "    'Room': {'math': 0, 'gym': 1, 'reading': 2}},\n",
    "    \n",
    "    {'Sex': {0: 'male', 1: 'female'},\n",
    "    'Room': {0: 'math', 1: 'gym', 2: 'reading'}}\n",
    "    \n",
    "    >>>test.replace(revk, inplace=True)\n",
    "          Sex     Room  Age\n",
    "    0    male     math   11\n",
    "    1  female     math   29\n",
    "    2  female      gym   15\n",
    "    3    male      gym   16\n",
    "    4    male  reading   14\n",
    "        \n",
    "    '''\n",
    "    df = daf.copy(deep=True)\n",
    "    replace_key = {}\n",
    "    revert_key = {}\n",
    "    col_names = df.select_dtypes('object').columns\n",
    "    if dropna:\n",
    "        df.dropna(inplace=True)\n",
    "    for col in col_names:\n",
    "        uniques = list(df[col].unique())\n",
    "        temp_dict = {}\n",
    "        rev_dict = {}\n",
    "        for each_att in uniques:\n",
    "            temp_dict[each_att] = uniques.index(each_att)\n",
    "            rev_dict[uniques.index(each_att)] = each_att\n",
    "        replace_key[col] = temp_dict\n",
    "        revert_key[col] = rev_dict\n",
    "    df.replace(replace_key, inplace=True)\n",
    "    \n",
    "    return df, replace_key, revert_key\n",
    "\n",
    "def explore_validation_curve(X : pd.DataFrame, y : pd.DataFrame, param_grid : dict, model, cv=None, color_args={'train': ['black', 'orange'], 'test': ['red', 'cyan']}):\n",
    "    '''Function that will print out plot of the single or multiple input hyperparameter(s) for the validation\n",
    "    curves the plotted mean for each nth value and the standard deviation for each nth value. This requires\n",
    "    some model generated and will return a sklearn.model_select.GridSearchCV class.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pandas DataFrame\n",
    "        Some x_values dataframe to be put into the validation_curve.\n",
    "    \n",
    "    y : pandas DataFrame\n",
    "        Some y_values dataframe to be put into the validation_curve.\n",
    "    param_grid : str\n",
    "        What hyperparmeter you would like to explore within the validation_curve and an associated numpy range.\n",
    "        With each additional hyperparameter, you'll have combinatoric possibilities of \n",
    "        n!/r!(n âˆ’ r)!, where r is the number of hyperparameters and n is the number\n",
    "        of n values for each hyperparameter.\n",
    "        format :\n",
    "                        {\n",
    "                            __some_hyperparameter__: __some_numpy_range__,\n",
    "                            __some_hyperparameter__: __some_numpy_range__\n",
    "                        }\n",
    "        \n",
    "        Examples\n",
    "        --------\n",
    "        Single Hyperparameter\n",
    "        param_grid = {'n_estimators' : np.arange(1, 200, 2)}\n",
    "        \n",
    "        Multi Hyperparameter\n",
    "        param_grid = {'n_estimators' : np.arange(1, 200, 2),\n",
    "                      'max_depth' : np.arange(1, 13, 1)}\n",
    "    \n",
    "    model : Sklearn model\n",
    "        Can check sklearn models, verified currently compatible with:\n",
    "            DecisionTreeClassifier,\n",
    "            RandomForestClassifier,\n",
    "            KNeighborsClassifier\n",
    "            \n",
    "    cv : int, cross-validation generator or an iterable, default=None\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "        - None, to use the default 5-fold cross validation,\n",
    "        - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
    "        - :term:`CV splitter`,\n",
    "        - An iterable yielding (train, test) splits as arrays of indices.\n",
    "        For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
    "        either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
    "        other cases, :class:`KFold` is used.\n",
    "    color_args : dict\n",
    "        Not required, default values:\n",
    "        {'train': ['black', 'orange'],\n",
    "         'test': ['red', 'cyan']}\n",
    "        \n",
    "        can personalize but must be in the format of\n",
    "        # train_line    line_color      standard_dev fill color\n",
    "        {'train}    :   ['black'     ,  'orange']\n",
    "        # test_line    line_color      standard_dev fill color\n",
    "        {'test'}    :   ['red'     ,  'cyan']\n",
    "    Returns\n",
    "    -------\n",
    "    sklearn GridSearchCV\n",
    "        The returned class is a the GridSearchCV with associated selectable attributes.\n",
    "        \n",
    "    \n",
    "    Examples\n",
    "    -------\n",
    "    >>> param_grid = {'n_estimators' : np.arange(1, 200, 2),\n",
    "                      'max_depth' : np.arange(1, 13, 1)}\n",
    "                      \n",
    "    >>> val = explore_validation_curve(X_train, y_train, param_grid, RandomForestClassifier())\n",
    "    \n",
    "    >>> print(type(val))\n",
    "    \n",
    "    <class 'sklearn.model_selection._search.GridSearchCV'>\n",
    "    \n",
    "    --------------------------------------------------------------------------------------------------\n",
    "    >>> param_grid = {'n_estimators' : np.arange(1, 200, 2),\n",
    "                      'max_depth' : np.arange(1, 13, 1)}\n",
    "    \n",
    "    >>> val = explore_validation_curve(X_train, y_train, param_grid, DecisionTreeClassifier(), cv=5,\n",
    "                                color_args={'train': ['green', 'purple'],\n",
    "                                            'test': ['orange', 'red']})\n",
    "    >>> print(type(val))\n",
    "    \n",
    "    <class 'sklearn.model_selection._search.GridSearchCV'>\n",
    "    --------------------------------------------------------------------------------------------------\n",
    "    >>> param_grid = {'n_neighbors' : np.arange(1, 30, 2),\n",
    "                      'max_depth' : np.arange(1, 13, 1)}\n",
    "    \n",
    "    >>> val = explore_validation_curve(X_train, y_train, param_grid, KNeighborsClassifier(), cv=5,\n",
    "                                color_args={'train': ['green', 'purple'],\n",
    "                                            'test': ['orange', 'red']})\n",
    "    >>> print(type(val))\n",
    "    \n",
    "    <class 'sklearn.model_selection._search.GridSearchCV'>\n",
    "    '''\n",
    "    \n",
    "    # Check that if the param_name is 'max_depth' that the range is not greater than the number of attributes in model.\n",
    "    if 'max_depth' in param_grid.keys() and len(param_grid['max_depth']) > X.shape[1]:\n",
    "        raise Exception(f\"Sorry, your range cannot be larger than the number of attributes ({X.shape[1]}) when using 'max_depth\")\n",
    "        \n",
    "    # Calculate validation curve and return as array\n",
    "    grid = GridSearchCV(model, param_grid, cv=cv, return_train_score=True)\n",
    "    grid.fit(X, y)\n",
    "\n",
    "    ## Results from grid search\n",
    "    results = grid.cv_results_\n",
    "    means_test = results['mean_test_score']\n",
    "    stds_test = results['std_test_score']\n",
    "    means_train = results['mean_train_score']\n",
    "    stds_train = results['std_train_score']\n",
    "\n",
    "    ## Getting indexes of values per hyper-parameter\n",
    "    masks=[]\n",
    "    best_vals = dict()\n",
    "    masks_names= list(grid.best_params_.keys())\n",
    "    for p_k, p_v in grid.best_params_.items():\n",
    "        best_vals[p_k] = p_v\n",
    "        masks.append(list(results['param_'+p_k].data==p_v))\n",
    "\n",
    "    params=grid.param_grid\n",
    "\n",
    "    ## Ploting results\n",
    "    pram_preformace_in_best = {}\n",
    "    for i, p in enumerate(masks_names):\n",
    "        plt.title(f'Validation Curve for {p}')\n",
    "        # Check if there is only 1 hyperparameter to test\n",
    "        if len(masks_names) > 1:\n",
    "            # Stack the masks to find the best index\n",
    "            m = np.stack(masks[:i] + masks[i+1:])\n",
    "            pram_preformace_in_best\n",
    "            best_parms_mask = m.all(axis=0)\n",
    "            # Map the best index \n",
    "            best_index = np.where(best_parms_mask)[0]\n",
    "        else:\n",
    "            best_index = np.arange(len(means_test))\n",
    "        x = np.array(params[p])\n",
    "        # Find the test_mean and train mean for each hyperparameter\n",
    "        test_mean = np.array(means_test[best_index])\n",
    "        test_std = np.array(stds_test[best_index])\n",
    "        train_mean = np.array(means_train[best_index])\n",
    "        train_std = np.array(stds_train[best_index])\n",
    "        best_mean = means_test[best_index][best_vals[p]-1]\n",
    "        # Build the plot for each hyperparameter\n",
    "        plt.plot(x, train_mean, label='Training score', color=color_args['train'][0])\n",
    "        plt.plot(x, test_mean, label='Test score', color=color_args['test'][0])\n",
    "        plt.fill_between(x, test_mean - test_std, test_mean + test_std, linestyle='--', label='test', color=color_args['test'][1])\n",
    "        plt.fill_between(x, train_mean - train_std, train_mean + train_std, linestyle='-', label='train' , color=color_args['train'][1])\n",
    "        plt.xlabel(p.upper())\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='best')\n",
    "        plt.annotate(f'Best {p} at N = {best_vals[p]}\\nat {best_mean:0.2f}',\n",
    "            xy=(best_vals[p], best_mean), xycoords='data',\n",
    "            xytext=(0, 20),\n",
    "            textcoords='offset points',\n",
    "            arrowprops=dict(arrowstyle=\"->\",\n",
    "                            connectionstyle=\"arc3\"))\n",
    "        plt.show()\n",
    "        \n",
    "    print(grid.best_params_)\n",
    "\n",
    "    # Return a GridSearchCV class with the associated attributes to examine.\n",
    "    return grid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
